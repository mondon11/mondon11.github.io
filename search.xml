<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Tensorflow Fall Symposium 2017 小记]]></title>
    <url>%2F2017%2F10%2F20%2FTensorflow%20Fall%20Symposium%202017%20%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[艺术的价值同其唤起的感情强度无关，后者可以无需艺术。 -昆德拉 CPU、GPU库：Intel: MKL-DNNNVIDIA: cuDNN 跨平台：2.1 deeplearn.js:deeplearn.js 是一个可用于机器智能并加速 WebGL 的开源 JavaScript 库。deeplearn.js 提供高效的机器学习构建模块，使我们能够在浏览器中训练神经网络或在推断模式中运行预训练模型。它提供构建可微数据流图的 API，以及一系列可直接使用的数学函数。2.2 Tensorflow serving:TensorFlow Serving 是一个用于机器学习模型 serving 的高性能开源库。它可以将训练好的机器学习模型部署到线上，使用 gRPC 作为接口接受外部调用。更加让人眼前一亮的是，它支持模型热更新与自动模型版本管理。这意味着一旦部署 TensorFlow Serving 后，你再也不需要为线上服务操心，只需要关心你的线下模型训练。2.3 Tensorflow lite:移动端在推断模式中运行预训练模型。Flatbuffers。 eager execution 及早执行：使对python语言更友好。 Cloud TPU:第一代：推理。第二代：训练+推理。脉动阵列（systolic array）系统。 数据处理：1.4版本: tf.data (之前版本为tf.contrib.data)异步多线程计算：Queue是TF队列和缓存机制的实现QueueRunner是TF中对操作Queue的线程的封装Coordinator是TF中用来协调线程运行的工具除了常用的feed，两个input接口:Dataset APIIterator API 高级API:1.4版本推出 tf.keras 最后祝你，身体健康，再见！]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Tensorflow seq2seq模型的聊天机器人的实现]]></title>
    <url>%2F2017%2F10%2F17%2F%E5%9F%BA%E4%BA%8ETensorflow%20seq2seq%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[To see a world in a grain of sandAnd a heaven in a wild flowerHold infinity in the palm of your handAnd eternity in an hour -William Blake 上面这首诗出自英国著名浪漫主义诗人威廉-布雷克。在“深度学习”被炒得火热的“大数据时代”，我们也应该从某一技术点切入，动手尝试之后能有所收获，做到“以管窥豹，可见一斑”自然是极好的了。这里我就从“Chatbot(聊天机器人)”说开去，简单讲一下基于Tensorflow seq2seq模型的聊天机器人的实现，算是抛砖引玉吧！ Chatbot的前世今生总的来看，Chatbot从诞生之初到现在，总共经历了三代： 第一代，关键词匹配检索阶段第一代Chatbot实现起来很简单，就是根据用户输入的关键词，从数据库中匹配得到相应的回答，以此回复用户。即便是在“人工智能”大肆“入侵”我们生活的今天，这类机器人也大量存在于我们的生活中，比如微信公众号的“回复xx得到相应文章”、运营商的“回复xx跳转服务”等等。不过，这类机器人只适用于问法明确的简单场景，当应用场景相对复杂时，这类机器人就需要维护一个非常庞大的关键词列表，而且这个列表很难覆盖全表达同一意义的不同的关键词，这就会影响到最终匹配的精度和结果。 第二代，在检索基础上引入自然语言处理（NLP）技术与第一代Chatbot相比，这一代机器人就显得更像人了：因为用户可以与它用句子交流而不是词了。利用自然语言处理（NLP）技术，如分词、词性标注等，把句子掰开揉碎，然后根据诸如词语加权检索等算法，在知识库中匹配检索得到最佳回答。从这一代机器人身上，我们可以看到些许“人工智能”的影子了：它似乎可以理解用户要表达的意思了。比如当用户以不同的问法提问时，如“我要订外卖”、“我想买外卖”等，聊天机器人会给出一致的合理的回答。不过，这一代机器人语义理解能力有限，匹配精度不高，而且由于问答策略是基于规则（或模板）的，这就需要大量的人工工作来维护知识库的完备性。尽管如此，这一代机器人还是比上一代机器人性能上有了显著的提升。 第三代，以神经网络为基础，引入深度学习等技术与上一代机器人相比，因为引入了“深度学习”技术，这一代机器人可以打破人工配置的规则，以一种数据驱动（data-driven）的方式，获得更好的自主学习能力和语义理解能力，可以处理更加口语化、多样化的问法，而且极大地减少了人工工作量。利用多层神经网络的巧妙搭建，这一代机器人可以自主地学习到句子的不同层次的抽象特征，从而在语义理解的能力上有了质的提高。但是这类机器人受制于训练语料库的规模，国内只有阿里“小蜜”、百度“度秘”等少数科技巨头把这一代聊天机器人应用于客服上。我们这里要讲的基于seq2seq模型的Chatbot就是属于第三代聊天机器人。为什么要用seq2seq模型呢？因为它火呀！我们所熟悉的大名鼎鼎的谷歌翻译，就是采用了这个模型，翻译效果我想大家都有目共睹吧！事实上，seq2seq模型只是属于Chatbot的对话生成（response generation）阶段，一个优秀的Chatbot还应该具有对话状态跟踪（dialog state tracking）机制和用户建模（user modeling）机制，这样既可以理解和捕捉用户的真实意图，又可以为用户个性化地定制私人bot。在这篇文章中，我们只讨论对话生成阶段，下面的章节我就带你一步步实现基于seq2seq模型的聊天机器人。 实现基于seq2seq模型的Chatbot我们先来看下seq2seq模型的基本结构。下面的动图来自谷歌官方项目seq2seq。谷歌也发布了他们用seq2seq模型进行神经机器翻译的demo。事实上，聊天机器人的对话生成和神经机器翻译十分相似，无非就是训练样本的差异罢了。可以看到，seq2seq 是一个 Encoder–Decoder 结构的网络，它的输入是一个序列，输出也是一个序列，这是一种end-to-end方式，seq2seq由此得名。为了更好的解释该模型的工作流程，我们再贴一张来自《Sequence to Sequence Learning with Neural Networks》一文的插图。这里，“ABC” 被“翻译”为“WXYZ” ，&lt;EOS&gt;代表一句话的结束。简单来说，作为Encoder的RNN把输入的可变长度的sequence表示成一个固定大小的状态向量（fixed-size state vector）（可以理解为进行了语义编码），而作为decoder的RNN，则根据encoder的vector（背景知识），将这个固定长度的向量变成可变长度的目标的信号序列。细心的你可能会发现，decoder就相当于对输入只知道梗概意思，而无法得到更多输入的细节，比如输入的位置信息。如果输入的句子比较短、意思比较简单，翻译起来还行，长了复杂了效果应该就不好了。事实上也正是如此。为了解决这一问题，学者们提出了一个attention机制（上面那个动图上也标志了attention）。用谷歌自己的话来说，attention机制使解码器更接近输入（allow the decoder more direct access to the input）， 使解码的每一阶段都兼顾输入（allow the decoder to peek into the input at every decoding step）。 语料准备计算机领域有句名言：“输入的是垃圾，输出的也是垃圾”（garbage in,garbage out）。这用在机器学习领域再贴切不过了。机器能学到什么，依赖于训练的输入，也就好比是人类的教材。为什么现在深度学习、数据挖掘领域的绝大部分成果都出自科技巨头？就是因为他们手握海量数据呀！在对市面上的中文语料资源做了比较充分的调研之后，从这里找到了一些不错的语料库。虽然只利用这些语料难以训练出一个优质的Chatbot，但是作为练手还是绰绰有余了。我这里选用小黄鸡语料，先来看下语料的格式吧：12345678910EM 呵/呵M 是/王/若/猫/的/。EM 不/是M 那/是/什/么/？EM 怎/么/了M 我/很/难/过/，/安/慰/我/~... 首先，采用sqlite数据库对语料按照&lt;ask,answer&gt;格式进行存储,以方便后续操作。存储后格式如下：其次，创建词汇表。为什么要创建词汇表呢？因为机器学习的模型是要以数字而非字符进行输入训练的，我们创建一个比较完备的词汇表后，就可以用索引号来表示某一个字，类似one-hot思想。那么怎么创建呢？可以有两种思路：第一种就是脱离我们采用的语料资源，直接利用常用汉字建一个词汇表；第二种就是考虑我们的语料资源，按照字的出现频率从大到小进行排序后选取前N个构建词汇表。大多数研究都是选用第二种方法，我们也一样，这里N取5000。也许你会问，如果某个字不在词汇表中怎么办？我们就用“&lt;unk&gt;”的索引号代替即可（&lt;unk&gt;、&lt;eos&gt;、&lt;pad&gt;、&lt;go&gt;要手动添加到词汇表）。最后，考虑到seq2seq的bucket机制，我们对已有的数据库进行拆分，按照&lt;ask,answer&gt;的规模生成4个不同的数据库。规模划分依据如下：123# We use a number of buckets and pad to the closest one for efficiency.# See seq2seq_model.Seq2SeqModel for details of how they work.buckets = [(5, 15), (10, 20), (15, 25), (20, 30)] 至于为什么seq2seq要采用bucket机制，因为虽然RNN在数学上是可以处理任意长度的数据的，但是，在TensorFlow中使用bucket的原因主要是为了工程实现的效率。这里有一个比较好的解释。经过以上三步，我们的语料准备阶段就告一段落了。 模型搭建模型的搭建可以参考谷歌发布的机器翻译模型的demo中的seq2seq_model.py，我这里就我模型中的几个细节部分进行简单的阐述。首先，Encoder、Decoder的RNN采用多层LSTM模型：1234# LSTM cellscell = tf.contrib.rnn.BasicLSTMCell(size)cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob = dropout)cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers) 其次，在对话生成、神经机器翻译中，训练的复杂度以及解码的复杂度和词汇表的大小成正比。当输出的词汇表很大时，传统的softmax由于要计算每一个类的logits就会有问题。我们采用sampled softmax方法来减小计算开销：1234567891011121314151617181920212223# Sampled softmax only makes sense if we sample less than vocabulary size.if num_samples &gt; 0 and num_samples &lt; self.target_vocab_size: w_t = tf.get_variable("proj_w", [self.target_vocab_size, size], dtype=dtype) w = tf.transpose(w_t) b = tf.get_variable("proj_b", [self.target_vocab_size], dtype=dtype) output_projection = (w, b) def sampled_loss(labels, logits): labels = tf.reshape(labels, [-1, 1]) # We need to compute the sampled_softmax_loss using 32bit floats to # avoid numerical instabilities. local_w_t = tf.cast(w_t, tf.float32) local_b = tf.cast(b, tf.float32) local_inputs = tf.cast(logits, tf.float32) return tf.cast( tf.nn.sampled_softmax_loss( weights=local_w_t, biases=local_b, labels=labels, inputs=local_inputs, num_sampled=num_samples, num_classes=self.target_vocab_size), dtype) softmax_loss_function = sampled_loss 再次，采用attention方法来解决长距离依赖关系问题：123456789101112# The seq2seq function: we use embedding for the input and attention.def seq2seq_f(encoder_inputs, decoder_inputs, do_decode): return tf.contrib.legacy_seq2seq.embedding_attention_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols=source_vocab_size, num_decoder_symbols=target_vocab_size, embedding_size=size, output_projection=output_projection, feed_previous=do_decode, dtype=dtype) 最后，创建get_batch()方法，来为每步训练的批量梯度下降提供batch大小的数据：123456789101112131415161718192021222324252627282930313233343536373839def get_batch(self, bucket_id, data): encoder_size, decoder_size = self.buckets[bucket_id] encoder_inputs, decoder_inputs = [], [] for encoder_input, decoder_input in data: encoder_input = data_utils.sentence_indice(encoder_input) decoder_input = data_utils.sentence_indice(decoder_input) # Encoder encoder_pad = [data_utils.PAD_ID] * ( encoder_size - len(encoder_input) ) encoder_inputs.append(list(reversed(encoder_input + encoder_pad))) # Decoder decoder_pad_size = decoder_size - len(decoder_input) - 2 decoder_inputs.append( [data_utils.GO_ID] + decoder_input + [data_utils.EOS_ID] + [data_utils.PAD_ID] * decoder_pad_size ) batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], [] # batch encoder for i in range(encoder_size): batch_encoder_inputs.append(np.array( [encoder_inputs[j][i] for j in range(self.batch_size)], dtype=np.int32 )) # batch decoder for i in range(decoder_size): batch_decoder_inputs.append(np.array( [decoder_inputs[j][i] for j in range(self.batch_size)], dtype=np.int32 )) batch_weight = np.ones(self.batch_size, dtype=np.float32) for j in range(self.batch_size): if i &lt; decoder_size - 1: target = decoder_inputs[j][i + 1] if i == decoder_size - 1 or target == data_utils.PAD_ID: batch_weight[j] = 0.0 batch_weights.append(batch_weight) return batch_encoder_inputs, batch_decoder_inputs, batch_weights 模型训练下面我们就实例化模型，然后喂数据进行训练。由于代码比较容易理解，我就直接贴上来了：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102def train(): # prepare data print('preparing data...') bucket_dbs = data_utils.read_bucket_dbs(FLAGS.buckets_dir) bucket_sizes = [] for i in range(len(buckets)): bucket_size = bucket_dbs[i].size bucket_sizes.append(bucket_size) print('Bucket &#123;&#125; has &#123;&#125; data'.format(i, bucket_size)) total_size = sum(bucket_sizes) print('Total data size: &#123;&#125; '.format(total_size)) # create model and train with tf.Session() as sess: model = create_model(sess, False) sess.run(tf.initialize_all_variables()) buckets_scale = [ sum(bucket_sizes[:i + 1]) / total_size for i in range(len(bucket_sizes)) ] # for nice display metrics = ' '.join([ '\r[&#123;&#125;]', '&#123;:.1f&#125;%', '&#123;&#125;/&#123;&#125;', 'loss=&#123;:.3f&#125;', '&#123;&#125;/&#123;&#125;', 'lr=&#123;:.5f&#125;' ]) bars_max = 20 for epoch_index in range(1, FLAGS.num_epoch + 1): print('Epoch &#123;&#125;:'.format(epoch_index)) time_start = time.time() epoch_trained = 0 batch_loss = [] previous_losses=[] current_step=0 loss=0 while True: # select one bucket random_number = np.random.random_sample() bucket_id = min([ i for i in range(len(buckets_scale)) if buckets_scale[i] &gt; random_number ]) data, data_in = model.get_batch_data( bucket_dbs, bucket_id ) encoder_inputs, decoder_inputs, decoder_weights = model.get_batch( bucket_dbs, bucket_id, data ) _, step_loss, output = model.step( sess, encoder_inputs, decoder_inputs, decoder_weights, bucket_id, False ) loss=step_loss/FLAGS.steps_per_checkpoint current_step+=1 # every steps_per_checkpoint check if decay learning rate # and save model if current_step % FLAGS.steps_per_checkpoint == 0: if len(previous_losses) &gt; 2 and loss &gt; max(previous_losses[-3:]): sess.run(model.learning_rate_decay_op) previous_losses.append(loss) loss = 0 if not os.path.exists(FLAGS.model_dir): os.makedirs(FLAGS.model_dir) model.saver.save(sess, os.path.join(FLAGS.model_dir, FLAGS.model_name)) epoch_trained += FLAGS.batch_size batch_loss.append(step_loss) time_now = time.time() time_spend = time_now - time_start time_estimate = time_spend / (epoch_trained / FLAGS.num_per_epoch) percent = min(100, epoch_trained / FLAGS.num_per_epoch) * 100 bars = math.floor(percent / 100 * bars_max) # display metrics sys.stdout.write(metrics.format( '=' * bars + '-' * (bars_max - bars), percent, epoch_trained, FLAGS.num_per_epoch, np.mean(batch_loss), data_utils.time(time_spend), data_utils.time(time_estimate),model.learning_rate.eval() )) sys.stdout.flush() if epoch_trained &gt;= FLAGS.num_per_epoch: break print('\n') # save model if not os.path.exists(FLAGS.model_dir): os.makedirs(FLAGS.model_dir) model.saver.save(sess, os.path.join(FLAGS.model_dir, FLAGS.model_name)) 模型测试Chatbot response的评价很难，虽然说可以借鉴机器翻译的自动评价方法BLEU来做，但效果不会太好。几乎每篇语言生成模型的paper都是会花钱雇人来做人工评价，设计一套评价机制来打分，人工的评价会更具有说服力。我们这里所说的模型测试只是让用户与机器人自由聊天，然后看下机器人的回答靠不靠谱。在控制台即可实现这样一种对话方式。我这里利用Flask进行了Chatbot的web端的部署，方便用户用浏览器与机器人对话：123456# Flask@app.route('/message', methods=['POST'])def response(): req_msg = request.form['msg'] res_msg = seq2seq.decode_line(sess, model, req_msg) return jsonify( &#123; 'text': res_msg &#125; ) 1234567891011121314151617181920212223242526272829303132333435def decode_line(sess, model, sentence): class TestBucket(object): def __init__(self, sentence): self.sentence = sentence # for generating response: feed one ask, no answer. def random(self): return sentence, '' # Which bucket does it belong to? bucket_id = min([ b for b in range(len(buckets)) if buckets[b][0] &gt; len(sentence) ]) # Get a 1-element batch to feed the sentence to the model. data, _ = model.get_batch_data( &#123;bucket_id: TestBucket(sentence)&#125;, bucket_id ) encoder_inputs, decoder_inputs, decoder_weights = model.get_batch( bucket_id, data ) # Get output logits for the sentence. _, _, output_logits = model.step( sess, encoder_inputs, decoder_inputs, decoder_weights, bucket_id, True ) # This is a greedy decoder - outputs are just argmaxes of output_logits. outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits] # return response sentence corresponding to outputs. ret = data_utils.indice_sentence(outputs) return ret 来看下效果吧（web前端设计来自undersail）。嗯，看来这个Chatbot表现的还算不错。 参考文章与链接 干货篇：一文看懂聊天机器人所有猫腻 智能聊天机器人这么火，为啥国人把它用到了客户服务上？ RNN Encoder–Decoder的attention机制简介 Sequence-to-Sequence Models Tensorflow官方translate模型 使用TensorFlow实现的Sequence to Sequence的聊天机器人模型 easybot 用于对话系统的中英文语料 Sutskever I, Vinyals O, Le Q V. Sequence to sequence learning with neural networks[J]. 2014, 4:3104-3112.]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>seq2seq</tag>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用python itchat库实现微信操控电脑]]></title>
    <url>%2F2017%2F10%2F11%2F%E5%88%A9%E7%94%A8python%20itchat%E5%BA%93%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E6%93%8D%E6%8E%A7%E7%94%B5%E8%84%91%2F</url>
    <content type="text"><![CDATA[古之为英雄豪杰者，不过面厚心黑而已。 - 李宗吾 最近因为要做微信版的智能客服系统，所以看了看有关wechat的api，发现了一个很好的python库itchat，于是乎想用它做一些好玩的有用的程序。想到最近挂机跑深度学习模型的痛楚，遂决定做一个微信版的remote-CMD，可以用手机微信远程监控电脑运行状态（截屏），同时可以远程通过命令提示符操作PC，实现远程运行程序、搜索电脑文件并下载到手机等“炫酷”的功能，先上代码吧！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#coding=utf8import itchatfrom PIL import ImageGrabimport timeimport osdef get_screen_img(filename): img=ImageGrab.grab() img.save(filename)@itchat.msg_register(itchat.content.TEXT)def get_content(msg): content=msg['Text'] if msg['ToUserName']=='filehelper': print content if content=='jp': print '$send screen image' time_now=time.strftime('%Y_%m_%d_%H_%M_%S',time.localtime(time.time())) picname=time_now+'.png' get_screen_img(picname) itchat.send('@img@'+picname,'filehelper') elif content.split()[0]=='xz': print '$send file' try: itchat.send_file(content.split()[1],'filehelper') except: itchat.send(u'命令无效!','filehelper') elif content.split()[0]=='cd': try: os.chdir(content.split()[1]) except: itchat.send(u'命令无效!','filehelper') elif content.split()[0]=='dir': try: ret=os.popen(content).read().decode('gbk') itchat.send(ret,'filehelper') except: itchat.send(u'命令无效或内部错误!','filehelper') else: try: ret=os.popen(content).read().decode('utf-8') itchat.send(ret,'filehelper') except: itchat.send(u'命令无效或内部错误!','filehelper') else: passitchat.auto_login(hotReload=True)itchat.run() 温馨小提示： 开发环境：win7 64bit + python 2.7 由于requests的编码问题，需要将fields.py文件放入 Lib\site-packages\urllib3下覆盖原文件才可传输中文名文件。（我的路径是C:\Users\mondon\Anaconda2\Lib\site-packages\urllib3，仅供参考。如果上面的下载链接打不开，可点击这个，将其复制下来另存为fields.py即可） 使用方法：3.1 首先需要添加“文件传输助手”为好友。以后的操作都是通过与“助手”文字对话完成的。3.2 运行程序，手机扫码登录。登录成功控制台会有提示。3.3 几个常见功能命令：截屏：jp下载：xz File (如 xz c:\test\1.txt)常见cmd：ls (查看当前路径下所有目录); cd FilePath (切换路径，如cd c:\test); dir File /s (查找文件，如 dir c:\ *23.txt /s，使下载更智能。查找比较耗时，稍加等待即可) … 最后祝你，身体健康，再见！]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>wechat</tag>
        <tag>itchat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随记2]]></title>
    <url>%2F2017%2F09%2F22%2F%E9%9A%8F%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[珍惜往事的人也一定有一颗温柔爱人的心。当我们的亲人远行或故世之后，我们会不由自主地百般追念他们的好处，悔恨自己的疏忽和过错。然而，事实上，即使尚未生离死别，我们所爱的人何尝不是时时刻刻离我们而去呢？浩渺宇宙间，任何一个生灵的降生都是偶然的，离去却是必然的；一个生灵与另一个生灵的相遇总是千载一瞬，分别却是万劫不复。说到底，谁和谁不同是这空空世界里的天涯论落人？在平凡的日常生活中，你已经习惯了和你所爱的人的相处，仿佛日子会这样无限延续下去。忽然有一天，你心头一凉，想起时光在飞快流逝，正无可挽回地把你、你所爱的人以及你们共同拥有的一切带走。于是，你心中升起一股柔情，想要保护你的爱人免遭时光劫掠。你还深切感到，平凡生活中这些简单的幸福也是多么宝贵，有着稍纵即逝的惊人的美… -周国平]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>散文</tag>
        <tag>周国平</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随记]]></title>
    <url>%2F2017%2F09%2F13%2F%E9%9A%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[人类所能期望的最高理想，不应是一具德行的陈列箱，而应是只去做一个和蔼可亲近情理的人。 -林语堂 今天在逛我爱自然语言处理博客时，看到了一系列很好的文章，叫做《正态分布的前世今生》，共8篇，来自RICKJIN。我特别喜欢这样深入浅出，娓娓而谈的文章，特地来记录分享下。另外推荐一本由C.R.Rao写的统计与真理-怎样运用偶然性，我觉得这种类型的文章书籍不受大众欢迎很难吧！]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>统计</tag>
        <tag>正态分布</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用python requests帮你选课（国科大教务系统）]]></title>
    <url>%2F2017%2F09%2F09%2F%E5%88%A9%E7%94%A8python%20requests%E5%B8%AE%E4%BD%A0%E9%80%89%E8%AF%BE%EF%BC%88%E5%9B%BD%E7%A7%91%E5%A4%A7%E6%95%99%E5%8A%A1%E7%B3%BB%E7%BB%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[记得以前有一个笑话，说让本科，硕士和博士分别炒一盘回锅肉。本科生找了一张菜谱，买了需要的食材和酱料，照着菜谱炒出来了；硕士生找了一些菜谱，进行了调研并且比较了不同菜谱的区别，选择了几个食材供应商进行对比，最后炒出了回锅肉并写了一篇炒回锅肉的报告；博士生回去进行了大量的调研，历时半年提交了一份一百多页的论文。翻开论文目录的第一章写着：如何养猪。 -李飞白 我想大家都遇到过这样的事吧：每当到了学期初选课的时候，校园网就瘫痪掉，等你费劲千辛万苦再次能进入选课系统时，想选的、限选的课都已经被抢光了。我这里提供一个方法，利用python requests库，帮你秒选课程。即使课程人数已经到了上限，也可以挂着程序一直运行，有人退课了你便会第一时间抢上。直接上代码吧！123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200#coding=utf-8import requestsimport reimport jsonimport timeconn=requests.session() #创建session，传递cookiedel_flag=0 #删除课程flagadd_flag=1 #新增课程flag#登录print ('登录中...')'''#第一种登录方式url='http://onestop.ucas.ac.cn/Ajax/Login/0'data=&#123; 'username':'xxx@xxx', #登录邮箱 'password':'xxxxxx', #登录密码 'remember':'checked'&#125;headers=&#123; 'Accept':'*/*', 'Accept-Encoding':'gzip, deflate', 'Accept-Language':'zh-CN,zh;q=0.8', 'Connection':'keep-alive', 'Content-Length':'64', 'Content-Type':'application/x-www-form-urlencoded; charset=UTF-8', 'Host':'onestop.ucas.ac.cn', 'rigin':'http://onestop.ucas.ac.cn', 'Referer':'http://onestop.ucas.ac.cn/home/index', 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36', 'X-Requested-With':'XMLHttpRequest'&#125;resp=conn.post(url=url,headers=headers,data=data)print ('登陆完成！')#进入选课系统print ('进入选课系统...')url=json.loads(resp.text)['msg']resp=conn.get(url=url)'''#第二种登录方式url='http://sep.ucas.ac.cn/slogin'headers=&#123; 'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Accept-Encoding':'gzip, deflate', 'Accept-Language':'zh-CN,zh;q=0.8', 'Cache-Control':'max-age=0', 'Connection':'keep-alive', 'Content-Length':'61', 'Content-Type':'application/x-www-form-urlencoded', 'Host':'sep.ucas.ac.cn', 'Origin':'http://sep.ucas.ac.cn', 'Referer':'http://sep.ucas.ac.cn/', 'Upgrade-Insecure-Requests':'1', 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36'&#125;data=&#123; 'userName':'xxx@xxx', #登录邮箱 'pwd':'xxxxxx', #登录密码 'sb':'sb'&#125;resp=conn.post(url=url,headers=headers,data=data)#准备进入选课系统url='http://sep.ucas.ac.cn/portal/site/226/821'resp=conn.get(url=url)reg=r'window.location.href=\'(.+?)\''url_reg=re.compile(reg)url_list=url_reg.findall(resp.text)url=url_list[0]resp=conn.get(url=url) #访问重定向的网址 进入选课系统#进入选择课程界面 获得query_string_parasurl='http://jwxk.ucas.ac.cn/courseManage/main'resp=conn.get(url=url)reg=r'\"?s=(.+?)\";'url_reg=re.compile(reg)query_list=url_reg.findall(resp.text)query_string_paras=query_list[0]#退课if del_flag: course_list=[ #构造要删除的课程号列表 136034 136064 ] count=1 while 1: print('=====================Round '+str(count)+'=========================') count=count+1 if not course_list: print ('课程全部退课成功！') break for i in course_list: url_del='http://jwxk.ucas.ac.cn/courseManage/del/'+str(i)+'?s='+query_string_paras try: resp=conn.get(url=url_del,timeout=3) except: continue success_reg=re.compile(u'成功') if success_reg.search(resp.text): course_list.remove(i) #从列表中删除这一门课 print (str(i)+' 退课成功！') else: print (str(i)+' 退课失败！') time.sleep(1)#选课if add_flag: ''' 需要手动构造data： 1.deptIds为学院id，即你要选的课程属于哪个学院 01-数学：910 02-物理：911 03-天文：957 04-化学：912 05-材料：928 06-生命：913 07-地球：914 08-资环：921 09-计算机：951 10-电子：952 11-工程：958 12-经管：917 13-公共管理：945 14-人文：927 15-外语：915 16-中丹：954 17-国际：955 18-存济：959 19-微电子：961 20-网络空间安全：963 21-未来技术：962 22-创新创业：？ 23-马克思：964 24-心理学：968 25-人工智能：969 26-纳米：970 27-艺术：971 TY-体育：946 2.sids为课程id，获得方式可以点击该课程，网址后面的6位数字即为课程id 3.加入did_xxxxxx:xxxxxx字段, 代表xxxxxx课程选为学位课 ''' data_list=[ &#123;'deptIds':'952','sids':'136055','did_136055':'136055'&#125;,#随机过程 学位课 &#123;'deptIds':'969','sids':'138246'&#125; #模式识别 ] url='http://jwxk.ucas.ac.cn/courseManage/saveCourse?s='+query_string_paras flag_dict=&#123;data['sids']:0 for data in data_list&#125; #0代表未选上 count=1 while 1: print('=====================Round '+str(count)+'=========================') count=count+1 #判断是否都选成功了 ''' flag=1 for i in flag_dict.values(): flag=flag*i if flag==1: break ''' if not data_list: #选课列表为空代表都选成功 print flag_dict #打印出flags验证 break #选课 for data in data_list: try: resp=conn.post(url=url,data=data,timeout=3) except: continue error_reg=re.compile(u'冲突') success_reg=re.compile(u'成功') if success_reg.search(resp.text): flag_dict[data['sids']]=1 #将这一门课的flag置1 data_list.remove(data) #从列表中删除这一门课 print (data['sids']+' 选课成功！') elif error_reg.search(resp.text): conflict_reg=re.compile(u'课程名称为(.+?)，') conflict=conflict_reg.findall(resp.text) conflict_course=conflict[0] print (conflict_course.encode('utf-8')+'，选课失败！') else: print (data['sids']+' 课程已选满，选课失败！等待退选...') time.sleep(1) 选课前提前几分钟运行程序即可，有可能有惊喜哦。另外本程序仅供学习使用，如果对教务系统造成不好的影响，我会及时撤稿。 最后打个广告，国科大同学关注下面的公众号，可以查询课程上课时间地点、校车余票等等，方便快捷！]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用python requests和bs4遍历下载某网站所有写真集]]></title>
    <url>%2F2017%2F09%2F04%2F%E5%88%A9%E7%94%A8python%20requests%E5%92%8Cbs4%E9%81%8D%E5%8E%86%E4%B8%8B%E8%BD%BD%E6%9F%90%E7%BD%91%E7%AB%99%E6%89%80%E6%9C%89%E5%86%99%E7%9C%9F%E9%9B%86%2F</url>
    <content type="text"><![CDATA[A thing of beauty is a joy forever. - John Keats 有研究表明，学习科研之余看看美女图片，有助于效率的提升。现在市面上有好多优质的写真集，比如推女郎、尤果网等等，这里我提供一个方法，利用python把所有优质写真集的所有期图片都下载下来。主要利用了requests和bs4这两个库：requests负责连接网络，处理http协议；bs4负责将网页变成结构化数据，方便爬取。下面我就直接贴代码了。python2.7可以成功运行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249#coding=utf-8import requestsfrom bs4 import BeautifulSoupimport reimport osimport timeimport threading'''获取不同杂志的入口网址列表'''def get_area_list(url): resp=conn.get(url=url,timeout=5) soup=BeautifulSoup(resp.content) raw_list=soup.findAll('dt') area_list=[] for item in raw_list: if item.find('a'): area_list.append(item.find('a').get('href')) return area_list'''获取某一杂志的网页总页数'''def get_page_num(url): resp=conn.get(url=url,timeout=5) soup=BeautifulSoup(resp.content) _list=soup.findAll('span') page=0 for item in _list: if item.has_attr('title'): ss = item.get('title') reg= re.compile(u'共(.+?)页') if reg.findall(ss): page=int(reg.findall(ss)[0].encode('utf8').strip()) break return page'''为了获得页数，必须访问非图片模式网址'''def get_noPicMode(url): resp=conn.get(url=url,timeout=5) soup=BeautifulSoup(resp.content) _list=soup.findAll('a') url_noPicMode='' for item in _list: if item.has_attr('class'): if item.get('class')==['chked']: url_noPicMode= item.get('href') return url_noPicMode'''获得某一页所有写真集网址列表'''def get_album_list(url): resp=conn.get(url=url,timeout=5) soup=BeautifulSoup(resp.content) _list=soup.findAll('a') album_list=[] for item in _list: if item.has_attr('onclick'): if item.get('onclick')=='atarget(this)': album_list.append(item.get('href')) return album_list'''获得某一写真集所有图片的网址列表和该写真集名字'''def get_pic_list(url): resp=conn.get(url=url,timeout=5) soup=BeautifulSoup(resp.content) _list=soup.findAll('img') pic_list=[] for item in _list: if item.has_attr('file'): pic_list.append(item.get('file')) _list=soup.findAll('span') album_name='others' for item in _list: if item.has_attr('id'): if item.get('id')=='thread_subject': album_name = item.string break return pic_list,album_name'''下载并保存图片'''def download_pic(url,album_name,pic_num,local_path,fl): count=0 while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url+' $Connect-error'+'\n') fl.flush() break try: resp = conn.get(url, stream=True,timeout=5) break except: continue try: if resp.status_code==200: s =album_name.encode('utf-8').replace('/',' ').decode('utf-8') with open(local_path+s+'/'+str(pic_num)+'.jpg', 'wb') as f: for chunk in resp.iter_content(chunk_size=1024): if chunk: f.write(chunk) f.flush() f.close() except: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url+' $Download-uncompleted'+'\n') fl.flush() return count'''主程序流程: 获得不同杂志的入口网址列表 -&gt; 判断某一杂志的入口网址是否为无图模式，从而获得该杂志的网页总页数 -&gt; 获得某一杂志某一页的所有写真集入口网址列表 -&gt; 获得某一写真集所有图片的网址列表和该写真集名字 -&gt; 如果本地未存在该写真集，下载。'''if __name__=='__main__': local_path='c:/Users/mondon/Desktop/test_mv/' #自定义保存路径 url_base='https://www.aisinei.com/' #网站基址 log='error_log.txt' #记录访问时抛错的网址 conn=requests.session() #创建session 传递cookie with open(local_path+log,'a') as fl: count=0 url_list=[] while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url_base+' $Connect-error'+'\n') fl.flush() break try: url_list=get_area_list(url_base) #获得不同杂志的入口网址列表 break except: continue for i in range(len(url_list)): count=0 url='' while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url_list[i]+' $Connect-error'+'\n') fl.flush() break try: #获得无图模式网址，为下面获得总页数做准备 if get_noPicMode(url_list[i]): url=get_noPicMode(url_list[i]) else: url=url_list[i] break except: continue page=0 if url: count=0 while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url+' $Connect-error'+'\n') fl.flush() break try: page=get_page_num(url) #获得某一杂志的总网页数 break except: continue for j in range(page): url=url_list[i].replace('1',str(j+1)) count=0 url_list_1=[] while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url+' $Connect-error'+'\n') fl.flush() break try: url_list_1=get_album_list(url) #获得某一网页的写真集网址列表 break except: continue for k in range(len(url_list_1)): count=0 url_list_2=[] album_name='' while 1: count=count+1 if count&gt;10: time_now=time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())) fl.write(time_now+' : '+url_list_1[k]+' $Connect-error'+'\n') fl.flush() break try: url_list_2,album_name=get_pic_list(url_list_1[k]) #获得该写真集的所有图片地址和写真集名字 break except: continue if album_name: #若本地不存在该写真集，则创建文件夹准备存储 print '准备下载: '+album_name.encode('utf-8') s =album_name.encode('utf-8').replace('/',' ').decode('utf-8') if not os.path.exists(local_path+s): os.makedirs(local_path+s) else: print ' '+album_name.encode('utf-8')+' 已存在' continue for m in range(0,len(url_list_2),4): #四线程下载图片 threads = [] t1 = threading.Thread(target=download_pic,args=(url_list_2[m],album_name,m+1,local_path,fl)) threads.append(t1) if m+1&lt;len(url_list_2): t2 = threading.Thread(target=download_pic,args=(url_list_2[m+1],album_name,m+2,local_path,fl)) threads.append(t2) if m+2&lt;len(url_list_2): t3 = threading.Thread(target=download_pic,args=(url_list_2[m+2],album_name,m+3,local_path,fl)) threads.append(t3) if m+3&lt;len(url_list_2): t4 = threading.Thread(target=download_pic,args=(url_list_2[m+3],album_name,m+4,local_path,fl)) threads.append(t4) for t in threads: t.setDaemon(True) t.start() for t in threads: t.join(30) #30s超时时间 print m+1 fl.close() 如有侵权，请及时联系我，我会撤稿。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>requests</tag>
        <tag>bs4</tag>
        <tag>beautifulsoup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用python requests帮你评教（国科大教务系统）]]></title>
    <url>%2F2017%2F08%2F29%2F%E5%88%A9%E7%94%A8python%20requests%E5%B8%AE%E4%BD%A0%E8%AF%84%E6%95%99%EF%BC%88%E5%9B%BD%E7%A7%91%E5%A4%A7%E6%95%99%E5%8A%A1%E7%B3%BB%E7%BB%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Talk is cheap, show me the code. -Linus Torvalds 在国科大，如果你错过了评教，就看不到该课程的成绩，是不是很烦。我这里提供一个方法，即使你错过了评教时间，也能评教然后看到成绩。主要利用python的requests库，python2 和 python3 都测试成功。直接上代码吧! 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#coding=utf-8import requestsimport reimport jsonimport randomimport numpy as np#创建session，传递cookieconn=requests.session()#登录print ('登录中...')url='http://onestop.ucas.ac.cn/Ajax/Login/0'data=&#123; 'username':'xxx@xxx', #你的登录邮箱 'password':'xxxxxx', #你的密码 'remember':'checked'&#125;headers=&#123; 'Accept':'*/*', 'Accept-Encoding':'gzip, deflate', 'Accept-Language':'zh-CN,zh;q=0.8', 'Connection':'keep-alive', 'Content-Length':'64', 'Content-Type':'application/x-www-form-urlencoded; charset=UTF-8', 'Host':'onestop.ucas.ac.cn', 'rigin':'http://onestop.ucas.ac.cn', 'Referer':'http://onestop.ucas.ac.cn/home/index', 'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36', 'X-Requested-With':'XMLHttpRequest'&#125;resp=conn.post(url=url,headers=headers,data=data)print ('登陆完成！')#进入选课系统print ('进入评教系统...')url=json.loads(resp.text)['msg']resp=conn.get(url=url)url='http://sep.ucas.ac.cn/portal/site/226/821'resp=conn.get(url=url)reg=r'window.location.href=\'(.+?)\''url_reg=re.compile(reg)url_list=url_reg.findall(resp.text)url=url_list[0]resp=conn.get(url=url) #访问重定向的网址 进入选课系统#进入选择课程界面 获得query_string_parasurl='http://jwxk.ucas.ac.cn/courseManage/main'resp=conn.get(url=url)reg=r'\"?s=(.+?)\";'url_reg=re.compile(reg)query_list=url_reg.findall(resp.text)query_string_paras=query_list[0]#获取所选课程id号url='http://jwxk.ucas.ac.cn/courseManage/selectedCourse'resp=conn.get(url=url)reg=r'courseplan/+(.+?)\"'course_reg=re.compile(reg)course_list=course_reg.findall(resp.text)#评教print ('评教中,请耐心等待...')comment=&#123; '1':'老师认真负责，作业布置的也十分合理，一学期下来收获很多', '2':'老师讲的好，同学们听得都很认真，作业量也适中，希望老师继续保持下去', '3':'老师的课讲得好，作业布置的合理，好好学能有很大收获' &#125;data=&#123;str(x):'900' for x in np.arange(900)&#125;data_other=&#123; #5星 和 评价 'starFlag':'5', 'flaw':'', 'suggest':''&#125;data.update(data_other)for course in course_list: url='http://jwxk.ucas.ac.cn/evaluate/save/'+course+'?s='+query_string_paras data_merit=&#123;'merit':comment[random.choice(['1','2','3'])]&#125; data_new=data.copy() data_new.update(data_merit) resp=conn.post(url=url,data=data_new)print ('评教完成！') 本程序仅供学习使用，如对教务系统造成影响，我会撤稿。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Flask为对答机器人写个RESTful API]]></title>
    <url>%2F2017%2F08%2F22%2F%E4%BD%BF%E7%94%A8Flask%E4%B8%BA%E5%AF%B9%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%86%99%E4%B8%AARESTful%20API%20%2F</url>
    <content type="text"><![CDATA[During his own Google interview, Jeff Dean was asked the implications if P=NP were true. He said, “P = 0 or N = 1.” Then, before the interviewer had even finished laughing, Jeff examined Google’s public certificate and wrote the private key on the whiteboard. LOL 上一篇文章讲了基于Tensorflow seq2seq 的对答机器人在阿里云上的部署（Flask+Nginx+Gunicorn），这里打算动手写个简单的RESTful API ，方便大家调用。因为我是个刚入门web开发的新手，所以这篇文章算是一个对实践的小小总结吧。 RESTful API 简介这里有个关于RESTful API的通俗易懂的解释，写的很好，我就简单引用其中一段话吧： 大家都知道”古代”网页是前端后端融在一起的，比如之前的PHP，JSP等。在之前的桌面时代问题不大，但是近年来移动互联网的发展，各种类型的Client层出不穷，RESTful可以通过一套统一的接口为 Web，iOS和Android提供服务。另外对于广大平台来说，比如Facebook platform，微博开放平台，微信公共平台等，它们不需要有显式的前端，只需要一套提供服务的接口，于是RESTful更是它们最好的选择。 -覃超 Flask实现RESTful API首先来说下HTTP的几种请求方式： HTTP定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。URL全称是资源描述符，我们可以这样认为：一个URL地址，它用于描述一个网络上的资源，而HTTP中的GET，POST，PUT，DELETE就对应着对这个资源的查，改，增，删4个操作。 -hyddd POST请求方式我之前写过简单的爬虫程序，发现POST和GET是两种最常用的请求方式。我们先动手实践下POST请求方式，完成”客户端发送什么，服务器端就返回什么”这样一个任务，然后在客户端打印出结果验证下：创建client.py：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=&#123;'msg':'hello'&#125;req = requests.post(url=url,data=data) print (req.content) 创建server.py：12345678910111213141516171819202122#coding=utf-8#server.pyfrom flask import Flask, requestimport jsonapp = Flask(__name__)app.debug = True@app.route('/api', methods=['POST'])def api(): if request.method == 'POST': dict_data=request.form #type:ImmutableMultiDict return dict_data['msg'] else: return 'not POST'@app.route('/')def index(): return 'hello world!'if __name__ == '__main__': app.run(host='127.0.0.1', port=5000) 运行server.py，然后运行client.py，会输出’hello’，交互成功！我们也可以添加报头，服务端根据报头中的Content-Type字段来获知请求中的消息主体是用何种方式进行编码，再对消息主体进行解析。我们将上面的代码稍作改动，添加Content-Type为application/x-www-form-urlencoded的报头，以form表单提交数据：创建client.py：12345678910#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=&#123;'msg':'hello'&#125;headers=&#123;'Content-Type':'application/x-www-form-urlencoded'&#125;req = requests.post(url=url,headers=headers,data=data)print (req.content) server.py不变运行server.py，然后运行client.py，会输出’hello’，交互成功！实际上，第一个例子中，报头会自动添加application/x-www-form-urlencoded的Content-Type，所以这里server.py不变没有问题。当然，我们还可以以json字符串形式提交数据，添加Content-Type为application/json的报头：创建client.py12345678910#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=json.dumps(&#123;'msg':'hello'&#125;)headers=&#123;'Content-Type':'application/json'&#125;req = requests.post(url=url,headers=headers,data=data)print (req.content) 创建server.py12345678910111213141516171819202122#coding=utf-8#server.pyfrom flask import Flask, requestimport jsonapp = Flask(__name__)app.debug = True@app.route('/api', methods=['POST'])def api(): if request.method == 'POST': dict_data=request.get_json() #dict return dict_data['msg'] else: return 'not POST'@app.route('/')def index(): return 'hello world!'if __name__ == '__main__': app.run(host='127.0.0.1', port=5000) 运行server.py，然后运行client.py，会输出’hello’，交互成功！但是如果我们去掉Content-Type为application/json的报头：创建client.py：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=json.dumps(&#123;'msg':'hello'&#125;)req = requests.post(url=url,data=data)print (req.content) server.py不变。运行server.py，然后运行client.py，server端会报错！！！原来报头不会自动添加application/json的Content-Type，服务器端不能将请求数据解析为json，所以此时request对象的json属性为None，用get_json()方法自然就不行了。别慌，我们对server.py做如下改动即可：创建server.py:1234567891011121314151617181920212223#coding=utf-8#server.pyfrom flask import Flask, requestimport jsonapp = Flask(__name__)app.debug = True@app.route('/api', methods=['POST'])def api(): if request.method == 'POST': str_data=request.get_data() #str dict_data=json.loads(str_data) #dict return dict_data['msg'] else: return 'not POST'@app.route('/')def index(): return 'hello world!'if __name__ == '__main__': app.run(host='127.0.0.1', port=5000) 运行server.py，然后运行client.py，会输出’hello’，交互成功！ GET请求方式我们再来实践下GET请求：创建client.py：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=&#123;'msg':'hello'&#125;req = requests.get(url=url,params=data)print (req.content) 创建server.py：12345678910111213141516171819202122#coding=utf-8#server.pyfrom flask import Flask, requestimport jsonapp = Flask(__name__)app.debug = True@app.route('/api', methods=['GET'])def api(): if request.method == 'GET': dict_data=request.args #type=ImmutableMultiDict return dict_data['msg'] else: return 'not GET'@app.route('/')def index(): return 'hello world!'if __name__ == '__main__': app.run(host='127.0.0.1', port=5000) 运行server.py，然后运行client.py，会输出’hello’，交互成功！其实，我们在client.py加入1print (req.url) 看到输出的url为http://127.0.0.1:5000/api?msg=hello ，也就是说，GET请求的数据会附在url之后（就是把数据放置在HTTP协议头中），以?分割url和传输数据，并且参数之间以&amp;相连。我们在本地浏览器访问http://127.0.0.1:5000/api?msg=nice ，就可以看到网页显示’nice’。这里有Flask API的说明，可以看下”进入的请求对象”这一部分了解下request的属性和方法。 状态码和错误处理最后再来讲下状态码和错误处理，这也是很重要的。我们比较熟悉的状态码有200-OK，400-Bad Request，404-Not Found，500 Internal Server Error等。正常情况下，用户将得到正确的结果，此时HTTP状态为200-OK ，但如果用户调用API的方式不当，服务器将会返回对应的错误，用户就可以根据状态码来判断错误类型进而调整调用方法。但是，默认的错误信息比较笼统，比如返回400-Bad Request时，到底请求哪里出了问题，用户也很难判断。我们在使用Flask设计RESTful API时，可以使用@error_handler修饰器覆盖默认的Flask错误处理，自定义错误信息的描述，方便用户修改错误。举个例子：我们创建server.py：1234567891011121314151617181920212223242526272829303132#coding=utf-8#server.pyfrom flask import Flask, request,jsonifyimport jsonapp = Flask(__name__)app.debug = True@app.route('/api', methods=['GET'])def api(): if request.method == 'GET': dict_data=request.args #ImmutableMultiDict return dict_data['msg'] else: return bad_method()@app.errorhandler(405)def bad_method(error=None): message=&#123; 'status':405, 'message':'HTTP method only allows GET' &#125; resp=jsonify(message) resp.status_code=405 return resp@app.route('/')def index(): return 'hello world!'if __name__ == '__main__': app.run(host='127.0.0.1', port=5000) 创建client.py：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl = 'http://127.0.0.1:5000/api'data=&#123;'msg':'hello'&#125;req = requests.post(url=url,data=data) print (req.content) 运行server.py，然后运行client.py，会输出：1234&#123; "message": "HTTP method only allows GET", "status": 405&#125; 看到这样的返回信息，我想用户很清楚调用API时错在哪了吧。 对答机器人的调用示例在我的项目中，所有的API访问都是通过HTTP请求的方式。并且需要从http://101.200.59.7/api 进行访问。只支持GET和POST方式的HTTP请求。看下微信公众平台的调用效果吧：因为语料和模型还不完善，对答机器人还有些“弱智”。你可以加下面的公众号体验一下： GET方式：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl='http://101.200.59.7/api'data=&#123;'msg':'吃了吗？'&#125;req = requests.get(url=url,params=data)print (req.content) POST方式：123456789#coding=utf-8#clent.pyimport requestsimport jsonurl='http://101.200.59.7/api'data=&#123;'msg':'吃了吗？'&#125;req = requests.post(url=url,data=data)print (req.content) 12345678910#coding=utf-8#clent.pyimport requestsimport jsonurl='http://101.200.59.7/api'data=&#123;'msg':'吃了吗？'&#125;headers=&#123;'Content-Type':'application/x-www-form-urlencoded'&#125;req = requests.post(url=url,headers=headers,data=data)print (req.content) 123456789#coding=utf-8#clent.pyimport requestsimport jsonurl='http://101.200.59.7/api'data=json.dumps(&#123;'msg':'吃了吗'&#125;)req = requests.post(url=url,data=data)print (req.content) 12345678910#coding=utf-8#clent.pyimport requestsimport jsonurl='http://101.200.59.7/api'data=json.dumps(&#123;'msg':'吃了吗'&#125;)headers=&#123;'Content-Type':'application/json'&#125;req = requests.post(url=url,headers=headers,data=data)print (req.content) 错误响应： HTTP状态码 错误信息 说明 400 msg must exist 数据必须以’msg’:’your data’形式传入 400 Content-Type must be application/json or application/x-www-form-urlencoded 报头只支持json和form两种形式 405 HTTP method must be GET or POST HTTP请求只支持GET和POST 其他错误请参考这里。 遇坑小记以上示例代码在python2.7环境可以成功运行。在python3环境中需要注意： POST以不加报头的json形式传输数据时，对于服务器端，python3上 request.headers没有’Content-Type’这一项，而python2上’Content-Type’为空。 python3最重要的新特性大概要算是对文本和二进制数据作了更为清晰的区分。python3 flask request.get_data()方法返回bytes，转成string需要decode(‘ascii’)。而python2 flask request.get_data()返回string。客户端打印结果req.content也有bytes和string的差别。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>RESTful</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tensorflow+Flask+Nginx+Gunicorn 在阿里云的部署]]></title>
    <url>%2F2017%2F08%2F21%2FTensorflow%2BFlask%2BNginx%2BGunicorn%E5%9C%A8%E9%98%BF%E9%87%8C%E4%BA%91%E7%9A%84%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[生命在于折腾！ -某网友 最近在做一个基于Tensorflow seq2seq 模型的对答机器人项目。模型的训练已经在本地完成（ubuntu 16.04 + python 3.5 +Tensorflow 1.2.1），对答也可以在本地用命令行形式进行，但是我并不满足这样的一种“枯燥”的展示方式，毕竟生命在于折腾，我决定尝试下Web端展示。因为是第一次做python web开发，所以我的原则是用什么学什么。在做了简单的调研后，我决定采用下面的方式部署： vps：阿里云（学生有特惠） Web框架：Flask（简单易上手） 服务器：Gunicorn+Nginx（稳定有效） PS：本地系统是64位windows 7（另一台ubuntu主机在训练模型，卡的不行…） vps上的预准备先来看下我租用的主机的配置吧，这个是最便宜的，对于我的应用足够了。（公网IP就是我项目的地址，欢迎访问。）在开始部署之前，我建议阅读下帮助与文档，特别是对于像我一样的小白，可以少走不少弯路。首先，我们要建立本地与vps的连接，来完成本地对远程服务器的模拟。Xshell、Putty等工具都可以，我采用的是Putty，具体步骤可以参考使用 SSH 密钥对连接 Linux 实例。可是，按照步骤走下来，我们却发现连接不成功。我尝试ping了一下公网IP，居然也ping不通。原来，我们的安全组规则没有配置好。参考ECS实例安全组默认的公网规则被删除导致无法ping通： 端口范围： 建议只开放 TCP 协议的端口 22 （用于 SSH） 、3389 （用于远程桌面）和 ICMP 协议（用户 PING 探测），用于探测和远程连接。 添加这些安全组规则后，终于连接成功！1Welcome to Alibaba Cloud Elastic Compute Service ! 接下来，我们在vps上安装配置ftp服务，为后面上传项目代码做准备。具体可以参考centos 7 安装配置ftp服务。同样的问题又出现了，我们用Filezilla连接阿里云，发现连不上，原来和上面的那个问题一样，我们需要开放 TCP 协议的端口 20、21，做法和上面一样。另外，如果我们想上传文件到服务器上的某一文件夹中，我们需要修改该文件夹权限：1# chmod -R 777 [文件夹] 至此，vps上的预准备完成。 利用Anaconda安装TensorflowCentOS自带python2，因为我开发环境是python3，所以需要安装python3。并且，还要安装Tensorflow。这里我推荐用Anaconda，方便快捷。首先，在本地下载对应版本的Anaconda，我这里选择的是Python 3.6 version。下载完成后，用FileZilla将其上传至服务器某一目录下，在putty上，cd到该目录，完成安装：1# bash Anaconda3-4.4.0-Linux-x86_64.sh 然后，建立一个Tensorflow的运行环境，并在conda环境中安装Tensorflow：123# conda create -n tensorflow python=3.5# source activate tensorflow# pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl 最后，测试安装是否成功：123456# python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello=tf.constant('hello world')&gt;&gt;&gt; sess=tf.Session()&gt;&gt;&gt; print (sess.run(hello))&gt;&gt;&gt; exit() 退出Tensorflow环境1# source deactivate 安装Flask+Nginx+Gunicorn首先安装Flask：12# source activate tensorflow# pip install flask 然后我们测试下Flask是否安装成功。我们在本地创建个hello.py：1234567891011from flask import Flaskapp = Flask(__name__)app.debug=True@app.route('/')def hello_world(): return 'Hello World!'if __name__ == '__main__': app.run(host='0.0.0.0',port=5000) 将此文件上传至服务器 /home/mondon/www/my_flask中（你可以自定义），在putty上cd到此目录下，运行此文件：1# python hello.py 这时，你在本地打开浏览器，输入你的公网IP和端口号（我是101.200.59.7:5000），会看到网页上显示如下，表明Flask安装成功。按Ctrl+C退出运行hello.py。 我们知道 Flask 中自带了 web server，通过 Werkzeug，我们可以搭建 WSGI 服务，运行我们的网站，但 Flask 是 Web 框架，并不是 Web 服务器，尽管 Werkzeug 很强大，但只能用于开发，不能用于生产。 -knarfeh 生产环境中，通常采用Gunicorn/uWSGI+Nginx的组合作为web服务器，因为我没有什么web开发经历，对此了解也不深，就先跟着老司机走了。下面安装Nginx：1# yum install nginx 修改Nginx默认配置，我的Nginx配置文件在 /etc/nginx/nginx.conf，修改nginx.conf中的如下位置的内容：1234567891011121314server &#123; listen 80 default_server; listen [::]:80 default_server; server_name 101.200.59.7; #你的公网IP root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://127.0.0.1:8000; # 这里是指向gunicorn host的服务地址，后面会讲。 proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; 然后运行Nginx：1# nginx 这时还是在本地浏览器输入你的公网IP，会有如下显示，Nginx配置完成：关闭nginx：1# nginx -s stop 我们再来安装Gunicorn：1# pip install gunicorn 好了，所有的配置已经完成，接下来就是如何启动我们的项目了。我们先cd到hello.py所在的目录下，然后依次启动Nginx、Gunicorn，我们的hello.py项目就启动了！（注意，这里127.0.0.1:8000 与上面nginx配置要一致）12# nginx# nohup gunicorn -b 127.0.0.1:8000 hello:app &amp; 访问公网IP来验证下： Tensorflow项目的部署既然”hello world”项目都已经实现了，Tensorflow项目也是如出一辙了。先来看下我项目的截图吧，Web前端设计来自undersail，很漂亮！在本地，我已经将模型训练好了，因此，我们只要把模型和代码一并上传。然后在启动文件中（类似于上面的hello.py），先初始化并加载模型，然后开始监听端口。有post请求时，将接收到的’msg’信息feed到我们的seq2seq模型，就可以得到对答机器人的回答了。项目代码已托管于github，我们下篇博客见~]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Flask</tag>
        <tag>vps</tag>
        <tag>Nginx</tag>
        <tag>Gunicorn</tag>
      </tags>
  </entry>
</search>
