<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Tensorflow + Flask + Nginx + Gunicorn 在阿里云的部署]]></title>
    <url>%2F2017%2F08%2F21%2FTensorflow%20%2B%20Flask%20%2B%20Nginx%20%2B%20Gunicorn%20%E5%9C%A8%E9%98%BF%E9%87%8C%E4%BA%91%E7%9A%84%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[生命在于折腾！ -某网友 最近在做一个基于Tensorflow seq2seq 模型的对答机器人项目。模型的训练已经在本地完成（ubuntu 16.04 + python 3.5 +Tensorflow 1.2.1），对答也可以在本地用命令行形式进行，但是我并不满足这样的一种“枯燥”的展示方式，毕竟生命在于折腾，我决定尝试下Web端展示。（下一篇Blog我将介绍下模型的实现。）因为是第一次做python web开发，所以我的原则是用什么学什么。在做了简单的调研后，我决定采用下面的方式部署： vps：阿里云（学生有特惠） Web框架：Flask（简单易上手） 服务器：Gunicorn+Nginx（稳定有效） PS：本地系统是64位windows 7（另一台ubuntu主机在训练模型，卡的不行…） vps上的预准备先来看下我租用的主机的配置吧，这个是最便宜的，对于我的应用足够了。（公网IP就是我项目的地址，欢迎访问。）在开始部署之前，我建议阅读下帮助与文档，特别是对于像我一样的小白，可以少走不少弯路。首先，我们要建立本地与vps的连接，来完成本地对远程服务器的模拟。Xshell、Putty等工具都可以，我采用的是Putty，具体步骤可以参考使用 SSH 密钥对连接 Linux 实例。可是，按照步骤走下来，我们却发现连接不成功。我尝试ping了一下公网IP，居然也ping不通。原来，我们的安全组规则没有配置好。参考ECS实例安全组默认的公网规则被删除导致无法ping通： 端口范围： 建议只开放 TCP 协议的端口 22 （用于 SSH） 、3389 （用于远程桌面）和 ICMP 协议（用户 PING 探测），用于探测和远程连接。 添加这些安全组规则后，终于连接成功！1Welcome to Alibaba Cloud Elastic Compute Service ! 接下来，我们在vps上安装配置ftp服务，为后面上传项目代码做准备。具体可以参考centos 7 安装配置ftp服务。同样的问题又出现了，我们用Filezilla连接阿里云，发现连不上，原来和上面的那个问题一样，我们需要开放 TCP 协议的端口 20、21，做法和上面一样。另外，如果我们想上传文件到服务器上的某一文件夹中，我们需要修改该文件夹权限：1# chmod -R 777 [文件夹] 至此，vps上的预准备完成。 利用Anaconda安装TensorflowCentOS自带python2，因为我开发环境是python3，所以需要安装python3。并且，还要安装Tensorflow。这里我推荐用Anaconda，方便快捷。首先，在本地下载对应版本的Anaconda，我这里选择的是Python 3.6 version。下载完成后，用FileZilla将其上传至服务器某一目录下，在putty上，cd到该目录，完成安装：1# bash Anaconda3-4.4.0-Linux-x86_64.sh 然后，建立一个Tensorflow的运行环境，并在conda环境中安装Tensorflow：123# conda create -n tensorflow python=3.5# source activate tensorflow# pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.1-cp35-cp35m-linux_x86_64.whl 最后，测试安装是否成功：123456# python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello=tf.constant('hello world')&gt;&gt;&gt; sess=tf.Session()&gt;&gt;&gt; print (sess.run(hello))&gt;&gt;&gt; exit() 退出Tensorflow环境1# source deactivate 安装Flask+Nginx+Gunicorn首先安装Flask：12# source activate tensorflow# pip install flask 然后我们测试下Flask是否安装成功。我们在本地创建个hello.py：1234567891011from flask import Flaskapp = Flask(__name__)app.debug=True@app.route('/')def hello_world(): return 'Hello World!'if __name__ == '__main__': app.run(host='0.0.0.0',port=5000) 将此文件上传至服务器 /home/mondon/www/my_flask中（你可以自定义），在putty上cd到此目录下，运行此文件：1# python hello.py 这时，你在本地打开浏览器，输入你的公网IP和端口号（我是101.200.59.7:5000），会看到网页上显示如下，表明Flask安装成功。按Ctrl+C退出运行hello.py。 我们知道 Flask 中自带了 web server，通过 Werkzeug，我们可以搭建 WSGI 服务，运行我们的网站，但 Flask 是 Web 框架，并不是 Web 服务器，尽管 Werkzeug 很强大，但只能用于开发，不能用于生产。 -knarfeh 生产环境中，通常采用Gunicorn/uWSGI+Nginx的组合作为web服务器，因为我没有什么web开发经历，对此了解也不深，就先跟着老司机走了。下面安装Nginx：1# yum install nginx 修改Nginx默认配置，我的Nginx配置文件在 /etc/nginx/nginx.conf，修改nginx.conf中的如下位置的内容：1234567891011121314server &#123; listen 80 default_server; listen [::]:80 default_server; server_name 101.200.59.7; #你的公网IP root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://127.0.0.1:8000; # 这里是指向gunicorn host的服务地址，后面会讲。 proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; 然后运行Nginx：1# nginx 这时还是在本地浏览器输入你的公网IP，会有如下显示，Nginx配置完成：关闭nginx：1# nginx -s stop 我们再来安装Gunicorn：1# pip install gunicorn 好了，所有的配置已经完成，接下来就是如何启动我们的项目了。我们先cd到hello.py所在的目录下，然后依次启动Nginx、Gunicorn，我们的hello.py项目就启动了！（注意，这里127.0.0.1:8000 与上面nginx配置要一致）12# nginx# nohup gunicorn -b 127.0.0.1:8000 hello:app &amp; 访问公网IP来验证下： Tensorflow项目的部署既然”hello world”项目都已经实现了，Tensorflow项目也是如出一辙了。先来看下我项目的截图吧，Web前端设计来自undersail，很漂亮！在本地，我已经将模型训练好了，因此，我们只要把模型和代码一并上传。然后在启动文件中（类似于上面的hello.py），先初始化并加载模型，然后开始监听端口。有post请求时，将接收到的’msg’信息feed到我们的seq2seq模型，就可以得到对答机器人的回答了。在下一篇blog中，我将介绍下这个对答机器人是如何实现的，敬请期待~]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Tensorflow</tag>
        <tag>Flask</tag>
        <tag>vps</tag>
        <tag>Nginx</tag>
        <tag>Gunicorn</tag>
      </tags>
  </entry>
</search>
